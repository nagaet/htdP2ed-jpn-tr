




インテルメッツォ5：計算のコスト

    具体的な時間、抽象的な時間

    「…のオーダーで」の定義

    なぜプログラムは述語とセレクタを使うのか？

========

以下のテストが成功したら、プログラムfについて何がわかるるでしょうか。

(check-expect (f 0) 0)
(check-expect (f 1) 1)
(check-expect (f 2) 8)


もし、この問題が普通のテストで出たら、こう答えるかもしれません。

    (定義済み (f x) (expt x 3))

しかし、次のことを語るものはない。

    (define (f x) (if (= x 2) 8 (* x x)))

テストは、ある入力に対してプログラムが期待通りに動作することだけを教えてくれる。

同じように、特定の入力に対してプログラムアプリケーションを評価するタイミングは、その入力に対する答えを計算するのにかかる時間を教えてくれるもので、それ以外のものではありません。データベース同じ入力が与えられたときに同じ答えを計算する2つのプログラム（prog-linearとprog-square）があり、選択されたすべての入力に対して、prog-linearは常にprog-squareよりも速く答えを計算することがわかるかもしれません。Making Choicesはまさにそのようなプログラムのペア、構造的に再帰的なプログラムであるgcdと、同等だが生成的再帰的なプログラムであるgcd-generativeを紹介します。タイミングを比較すると、後者は前者よりはるかに速いことがわかる。

                イメージ

    図176：2つの実行時間表現の比較

prog-squareの代わりにprog-linearを使いたいと思う自信はありますか？図176のグラフを考えてみてください。このグラフでは、X軸は入力のサイズ、例えばリストの長さを記録し、Y軸は特定のサイズの入力に対して答えを計算するのにかかる時間を記録しています。直線は prog-linear の実行時間、曲線は prog-square を表していると仮定します。陰影のある領域では、prog-linear は prog-square よりも時間がかかりますが、この領域の端では 2 つのグラフは交差し、その右側では prog-square の性能が prog-linear の性能よりも悪くなっています。もし、何らかの理由で、影のある領域の入力サイズに対してのみprog-linearとprog-squareの性能を評価し、クライアントが主に影でない領域に該当する入力でプログラムを実行するとしたら、間違ったプログラムを提供することになります。

このインターメッツォでは、プログラマはプログラムの性能について、その他の人は関数の成長について一般的な記述を行うことができるアルゴリズム解析の考え方を紹介します。（本書の初版をアルゴリズム解析と結びつけるためのメモを共有してくれたPrabhakar Ragde氏に感謝します。）真面目なプログラマや科学者なら、いずれこの概念に完全に精通する必要があります。これは、プログラムの性能属性を分析するための基礎となるものです。この考え方を正しく理解するためには、教科書を読みこなす必要がある。


具体的な時間、抽象的な時間

Making Choicesはgcdとgcd-generativeの実行時間を比較する。さらに、後者は前者よりも常に少ない再帰的ステップで答えを計算するため、より優れていると主張する。この考えを出発点として、『自己参照データ定義による設計』の簡単なプログラムであるhow-manyの性能を分析する。

(define (how-many a-list)
  (cond
    [(empty? a-list) 0]
    [else (+ (how-many (rest a-list)) 1)]))


未知の空でないリストの長さを計算するのにかかる時間を知りたいとします。Intermezzo 1: Beginning Student Languageにある計算のルールを使うと、このプロセスを一連の代数的操作として見ることができます。

(how-many some-non-empty-list)
==
(cond
  [(empty? some-non-empty-list) 0]
  [else (+ (how-many (rest some-non-empty-list)) 1)])
==
(cond
  [#false 0]
  [else (+ (how-many (rest some-non-empty-list)) 1)])
==
(cond
  [else (+ (how-many (rest some-non-empty-list)) 1)])
==
(+ (how-many (rest some-non-empty-list)) 1)

まず、how-manyの定義にあるa-listを実際の引数であるsome-non-empty-listに置き換えることで、最初のcond式が生成されます。次に

 (empty? some-non-empty-list)

仮定では結果は#falseである。問題は、この結果を決定するのにかかる時間です。正確な時間は分かりませんが、リストのコンストラクタをチェックするのには、わずかな固定時間がかかると言ってよいでしょう。実際、この仮定は次のステップでcondが最初の条件の値が何であるかをチェックするときにも成り立つ。これは#falseであるので、最初のcond行は削除される。elseで始まるcond行のチェックも同様に高速です。

(+ (how-many (rest some-non-empty-list)) 1)

最後に、restは一定の時間でリストの残りを取り出すと安全に仮定することができますが、そうでない場合は行き詰まったように見えます。how-manyがあるリストの長さを決定するのにかかる時間を計算するためには、how-manyがそのリストの残りの項目の数を数えるのにかかる時間を知る必要があります。

あるいは、述語とセレクタがある一定の時間を要すると仮定すると、 how-many がリストの長さを決定するのに要する時間は再帰的ステップの回数に依存する。より正確には、(how-many some-list)を評価するには、ある固定量のおよそn倍かかる。ここでnはリストの長さであり、同等に、プログラムが再帰する回数である。

この例から一般化すると、実行時間は入力の大きさに依存し、再帰的ステップの数は評価シーケンスの長さの良い推定値となることが示唆される。このため、コンピュータ科学者はプログラムの抽象的な実行時間を、入力の大きさと評価における再帰的ステップの数の関係として議論しています（抽象的とは、この尺度が原始的ステップにどれだけ時間がかかるかの詳細を無視するため）。最初の例では、入力の大きさはリスト上の項目数である。したがって、1個のリストには1ステップ、2個のリストには2ステップ、n個のリストにはnステップの再帰的ステップを必要とする。

コンピュータ科学者は、fの抽象的な実行時間について主張するために、a program f takes gon the order of n stepshという表現を使います。この表現を正しく使うためには、nについての説明、例えばgitは与えられたリストの項目の数を数える、あるいはgitは与えられた数の桁数である、というような説明を伴わないと、元の表現は実は無意味なのです。

すべてのプログラムが how-many のような単純で抽象的な実行時間を持つわけではありません。本書の最初の再帰的プログラムを見てみよう。

(define (contains-flatt? lo-names)
  (cond
    [(empty? lo-names) #false]
    [(cons? lo-names)
     (or (string=? (first lo-names) 'flatt)
         (contains-flatt? (rest lo-names)))]))


flatt'で始まるリストに対して、こう言います。

    (contains-flatt?
      (list "flatt" "robot" "ball" "game-boy" "pokemon"))

であれば、プログラムは再帰的なステップを必要としない。これに対して，'flatt'がリストの末尾に発生した場合は，次のようになる．

    (contains-flatt?
      (list "robot" "ball" "game-boy" "pokemon" "flatt"))

の場合、評価にはリストの項目数と同じ数の再帰的ステップが必要です。

この2つ目の分析から、プログラム分析の2つ目の重要な考え方である「どのような分析を行うか」ということが見えてくる。

    ベストケース分析では、プログラムが簡単に答えを見つけることができる入力の種類に注目します。この例では、'flatt'で始まるリストが最適な入力である。

    ワーストケース解析は、プログラムが最もストレスを感じる入力に対して、どの程度パフォーマンスが低下するかを判断するものです。contains-flatt?関数は、'flattが入力リストの末尾にあるときに最悪の性能を発揮する。

    最後に、平均解析は、プログラマは入力が常に最良の形であると仮定することはできず、入力が最悪の形でないことを望まなければならないという考えから出発している。多くの場合、プログラマはプログラムが要する平均時間を推定しなければならない。例えば，contains-flatt? は平均して入力リストの中間のどこかにある'flatt'を見つける．したがって，入力リストがn個の項目からなる場合，contains-flatt? の平均実行時間はimage，つまり入力にある項目の数の半分の頻度で再帰することになる．

したがって、コンピュータ科学者は通常、「平均値」または「最悪の場合」とともに、「順序」フレーズを使用します。

contains-flatt?が平均して1桁のイメージステッ プを使用するという考えに戻ると、抽象的な実行時間のもう一つの 特徴が見えてくる。それは、原始的な計算ステップ（述語のチェック、値の選択、cond句の選択）の評価にかかる正確な時間を無視するため、2による除算をやめることができる。仮定によれば、各基本ステップにはk単位の時間がかかり、つまり、contains-flatt?

    イメージ

もし、新しいコンピュータがあれば、これらの基本的な計算が2倍速くなるかもしれない。その場合、基本的な作業には定数としてイメージを使うことになる。この定数をcと呼んで計算することにしよう。

    イメージ

つまり、抽象的な実行時間は常にnに定数を掛けたものであり、"nのオーダーで"言えばそれが全てです。

ここで、図72のソートプログラムを考えてみよう。ここでは、小さな入力に対して、すべての再帰的ステップをリストアップし、手作業で評価しています。

(sort (list 3 1 2))
== (insert 3 (sort (list 1 2)))
== (insert 3 (insert 1 (sort (list 2))))
== (insert 3 (insert 1 (insert 2 (sort '()))))
== (insert 3 (insert 1 (insert 2 '())))
== (insert 3 (insert 1 (list 2)))
== (insert 3 (cons 2 (insert 1 '())))
== (insert 3 (list 2 1))
== (list 3 2 1)

評価では、sortが与えられたリストをどのように横断し、リストの各数値に対して挿入のアプリケーションをどのようにセットアップするかを示しています。別の言い方をすれば、sortは2段階のプログラムである。最初の段階では、sortの再帰的なステップは、リストの項目と同じ数の挿入のアプリケーションをセットアップします。第2段階では、insertの各アプリケーションがソートされたリストを巡回する。

アイテムを挿入することは、アイテムを見つけることと似ているので、insertとcontains-flatt?の性能が似ていることは驚くことではありません。l個のアイテムからなるリストに対してinsertを適用すると、0からl個の再帰的ステップを誘発する。平均すると、l/2が必要で、これはinsertがlステップの順番にかかることを意味する。lは与えられたリストの長さである。

問題は、これらのリストがどの程度の長さで、どのような数字を挿入するのかということです。上の計算を一般化すると、最初のものは画像アイテムの長さ、2番目のものは画像、といった具合に、空のリストに至るまでずっと長いことがわかります。従って、insertの実行は

    イメージ

意味

    イメージ

は、平均挿入ステップ数で最良の推測を表す。この最後の項では、n2が支配的な要素なので、ソート処理はn^2ステップのオーダーでかかると言う。演習486では、この主張をこのように単純化することがなぜ正しいかを論じなさい。

その理由については、演習486を参照してください。

また、より少ない形式と厳密さで進めることができる。sortはリストの各項目に一度だけinsertを使うので、"nのオーダーの"insertステップ（nはリストの大きさ）を得られます。insertは n/2 ステップを必要とするので、ソート処理には n・n/2 ステップか "n^2 のオーダー"が必要であることがわかる。

これらを合計すると、n個のアイテムからなるリストに対して、sortはnステップのオーダで、insertはn^2ステップの再帰的なステップを要することがわかります。それは

    n^2 + n

のステップになります。詳細は、再度演習486を参照してください。

注意 この解析は、リスト上の2つの項目を比較するのに一定の時間がかかると仮定しています。注意 終了

最後の例は、Local Definitionsのinfプログラムです。

(define (inf l)
  (cond
    [(empty? (rest l)) (first l)]
    [else (if (< (first l) (inf (rest l)))
              (first l)
              (inf (rest l)))]))

まずは(list 3 2 1 0) という小さな入力から始めます。結果は0であることが分かっている。次の例は、手による評価の最初の重要なステップです：

    (inf (list 3 2 1 0))
    ==
    (if (< 3 (inf (list 2 1 0)))
        3
        (inf (list 2 1 0)))

ここから、最初の再帰呼び出しを評価する必要がある。結果は0であり、したがって条件は#falseであるから、else-branchの再帰も評価しなければならない。

そうすると、(inf (list 1 0)) の評価が2つ表示されます。

    (inf (list 2 1 0))
    ==
    (if (< 2 (inf (list 1 0))) 2 (inf (list 1 0)))

この時点でパターンを一般化し、表にまとめることができる。

    元の表現                2個の評価を必要とする
    ---------------------   -------------------
    (inf (list 3 2 1 0))    (inf (list 2 1 0))
    (inf (list 2 1 0))      (inf (list 1 0))
    (inf (list 1 0))        (inf (list 0))

合計で、手による評価は4つの項目のリストに対して8つの再帰的ステップを必要とします。もし、リストの先頭に4が加われば、再帰的ステップの数はまた2倍になる。代数的に言えば、最後の数が最大であるとき、infはn個の数のリストに対して2^nのオーダーの再帰的ステップを必要とする。これはinfにとって明らかに最悪のケースである。

ここで止まってください。注意深く見ていれば、上記の提案が杜撰であることがわかるだろう。infプログラムは、実際には、n個のアイテムのリストに対して、2^(n-1) の再帰的ステップを必要とするだけである。何が起こっているのだろうか？

これまで"..のオーダーで" というとき、実際の時間を計測してきませんでした。組み込みの述語、セレクタ、コンストラクタ、演算など はすべてスキップする代わりに、再帰的なステップだけに注目することにしましょう。さて、次の計算を考えてみよう。

  2^(n-1) = 1/2 ・2^n

2^(n-1)と2^nは小さいな係数2 だけ異なります。"2^(n-1)ステップのオーダーで"というのは 2^n のステップ数で 実行されるinfプログラムに対して、*SLが提供するすべての基本操作が半分の 速度で実行される世界でのinfを記述していることになる。この意味で、この2つの表現は本当に同じことを意味している。問題は、 この2つの表現が具体的に何を意味しているかであり、それは次章の主題である。

練習問題484
降順でソートされたリストはinfにとって明らかに最悪の入力であるが、infの抽象的な実行時間の分析により、infをlocalで書き換えると実行時間が短縮される理由が説明される。便宜上、このバージョンをここに再現する。

 (define (infL l)
  (cond
    [(empty? (rest l)) (first l)]
    [else (local ((define s (infL (rest l))))
            (if (< (first l) s) (first l) s))]))

(infL (list 3 2 1 0)) を手で評価する。そして、infLは最良の場合にも最悪の場合にも"n ステップのオーダー"で使用することを論証してください。ここで、練習問題261をもう一度見てみるとよいだろう。

練習問題485
数列木とは、数または数列木の組のことである。木に含まれる数の和を求めるsum-treeを設計せよ。その抽象的な実行時間はどれくらいか？そのような木の大きさの許容できる尺度は何ですか？木の形状で最も悪いものは何ですか？最良の形は？

======
"...のオーダーで"の定義

前節では、"...のオーダーで" というフレーズの重要な構成要素をすべて挙げたが、次にこのフレーズの厳密な説明を紹介する。まず、前節で展開された2つの考え方から始めよう。

1. パフォーマンスの抽象的な測定は、入力の大きさと答えを決定するために必要な再帰的ステップの数という2つの量の関係である。この関係は、実際には、ある自然数（入力の大きさ）を別の自然数（所要時間）に対応させる数学的な関数である。

2. したがって、プログラムの性能に関する一般的な記述は、関数に関する記述であり、2つのプログラムの性能比較は、そのような2つの関数の比較を必要とする。

ある関数が他の関数より優れているかどうかは、どのように判断するのですか？

( 練習問題245は、別の問題、すなわち、他の二つのプログラムが等しいかどうかを決定するプログラムを定式化することができるかどうかという問題に取り組んでいます。このインターメッツォでは、プログラムを書くのではなく、平易な数学的議論を用いています )

冒頭の架空のプログラム、prog-linear と prog-square に戻ろう。両者は同じ結果を計算するが、その性能は異なる。prog-linearは "nステップのオーダー" を必要とし、prog-squareは "n^2ステップのオーダー" を必要とします。

    L(n) = c_L・n

であり、prog-squarefs の関連する性能関数は次のとおりです。

    S(n) = c_s・n^2

これらの定義において、cLはprog-squareにおける各再帰ステップのコスト、cSはprog-linearにおけるステップごとのコストである。

例えば、cL＝1000、cS＝1であることが分かったとする。そして、この抽象的な実行時間を集計して、比較を具体的にすることができるのです。


図176のグラフのように、同じ大きさのnの入力に対して、prog-squarefsの結果はprog-linearfsより小さいので、表は最初、prog-linearよりprog-squareが優れていると言うように見えます。しかし、表の最後の列を見てください。入力が十分に大きいと、prog-squarefsの優位性は減少し、入力サイズ1000で消滅します。それ以降、prog-square は常に prog-linear よりも遅くなります。

この最後の洞察が，gorder ofという言葉を正確に定義する鍵である．h もし，自然数に対する関数fが，すべての自然数に対してある関数gよりも大きな数を生成するなら，fはgよりも明らかに大きい．その場合でも、fはgより優れていると言いたい。そこで、次のような定義が成り立つ。

    定義 自然数上の関数gが与えられたとき、O(g) (pronounced: gbig-O of gh) は、自然数上の関数のクラスである。関数fは、以下のような数cとbigEnoughが存在するとき、O(g)のメンバーである。

        は、すべてのイメージに対して、イメージ

    用語説明 画像の場合、fはgより悪くないと言います。

当然ながら、この定義を先ほどのprog-linearとprog-squareの例で説明したいところです。Prog-linearとProg-squareの性能関数に定数を差し込んだものを思い出してください。

    イメージ

と

    イメージ

重要なのは、prog-squarefs の性能が prog-linearfs よりも悪くないことを検証するようなイメージのマジックナンバー c と bigEnough を見つけることです。今のところ、これらの数字が何であるかをお伝えするだけです。

    イメージ

これらの数値を用いて、以下のことを示す必要があります。

    イメージ

を、1000より大きなnの一つ一つについて計算します。このような論法が綴られているのは、次のようなことです。

    この条件を満たす特定のn0を選びます。

        イメージ

    n0という記号を使うのは、それについて特別な仮定をしないようにするためです。ここで、不等式の両辺に同じ正の係数をかけても、不等式が成り立つことを代数学で思い出してください。ここではn0を使う。

        イメージ

    このとき、不等式の左辺がL(n0)、右辺がS(n0)になっているだけであることを観察しておくとよい。

        イメージ

    n0は正しい種類の一般数なので、まさに示したかったことを示したことになる。

通常、このような議論を逆算してbigEnoughとcを見つけることができます。このような数学的推論は魅力的ですが、アルゴリズムの講座に譲りましょう。

Oの定義はまた、抽象的な実行時間の比較において特定の定数に注意を払う必要がない理由を、数学的に厳密に説明しています。例えば、プログレの各基本ステップを2倍速にすることができるとすると、次のようになります。

    イメージ

と

    イメージ

上記の議論は、bigEnoughを2倍の2000にすることで通ります。

最後に、多くの人はOを関数の略語と一緒に使っている。同様に、この使い方をすると、sortfs の最悪実行時間は O(n2) であり、incfs は O(2n) であると主張できます。

やめてください。関数の性能がO(1)であるとはどういう意味ですか？

練習問題486
最初のサブセクションで、関数 f(n) = n2 + n はクラス O(n2) に属すると述べた。この主張を検証する数cとbigEnoughの組を決定せよ。

練習問題487
g が O(f) に属することを示せ。これは抽象的に言って、f が g よりも高い（あるいは少なくとも同等に）ことを意味する。

練習問題488
image と image を比較せよ。f は O(g) に属するか、g は O(f) に属するか？


======
なぜプログラムは述語とセレクタを使うのですか？

このように、"順序 "という概念は、設計レシピが、よく整理されたプログラムと、 パフォーマンスの高いプログラムの両方を生成する理由を説明する。この洞察を、数字のリストから数字を探すプログラムの設計を例にとって説明する。以下は、署名、目的文、およびテストとして定式化された例である。

; Number [List-of Number] -> Boolean
; x は lの要素か？
(check-expect (search 0 '(3 2 1 0)) #true)
(check-expect (search 4 '(3 2 1 0)) #false)

その期待に応える2つの定義を紹介します。

(define (searchL x l)
  (cond
    [(empty? l) #false]
    [else
     (or (= (first l) x)
         (searchL
           x (rest l)))]))

(define (searchS x l)
  (cond
    [(= (length l) 0) #false]
    [else
     (or (= (first l) x)
         (searchS
           x (rest l)))]))

左のプログラムの設計は、設計レシピに準じている。特に、テンプレートの開発では、データ定義の節ごとに構造述語を 使うように呼びかけている。このアドバイスに従うと、最初のcond行が空リストを扱い、2番目のcond行がそれ以外を扱う条件付きプログラムが得られる。最初のcond行の質問はempty? を使い、2番目の質問はcons? or elseを使っている。

searchSのデザインは、構造的なデザインに沿うものではありませんそれは本当に生成的な再帰を使用しています。その代わりに、リストはサイズを持つコンテナであるという考えからヒントを得ている。したがって、プログラムはこのサイズが0かどうかをチェックすることができ、それは空虚さをチェックすることと等価である。

この考え方は機能的には正しいのですが、*SLが提供する操作のコストは固定定数であるという前提に立っています。しかし、長さが how-many のようなものであれば、searchS は searchL よりも遅くなるはずです。新しい用語を使うと、searchLはO(n)の再帰的ステップを使うのに対し、searchSはn個のアイテムのリストに対してO(n2)のステップを必要とするのです。要するに、条件を設定するために任意の*SL演算を使用すると、あるクラスの関数から性能が大幅に低下する可能性があるということです。

最後に、lengthが定数時間関数であるか、与えられたリストの長さに比例して時間を消費するかを調べる実験をしてみよう。最も簡単な方法は、長いリストを作成するプログラムを定義し、検索プログラムの各バージョンにかかる時間を測定することである。

; N -> [List Number Number]
; searchS と searchL はどれくらいの時間がかかるか
; nを (list 0 ... (- n 1)) で n を探すのにかかる時間
(define (timing n)
  (local ((define long-list
            (build-list n (lambda (x) x))))
    (list
      (time (searchS n long-list))
      (time (searchL n long-list)))))

さて、このプログラムを10000と20000で実行してみましょう。もし、lengthがempty? のようであれば、2回目の実行時間は1回目の実行時間のおよそ2倍になり、そうでなければ、searchSの時間は劇的に増加します。

ストップ!実験を行ってください。

実験を終えたと仮定すると、lengthは与えられたリストのサイズに比例して時間がかかることがわかったと思います。searchSの"S"は "squared" の略で、実行時間がO(n2)であるためです (他の言語がコンテナのサイズをどのように追跡するかについては、"アキュムレータを用いたデータ表現"を参照してください)。多くの言語では、コンテナの扱いが *SL とは異なっています。これがどのように行われるかを理解するには、もう1つの設計概念であるアキュムレータが必要で、本書の最後の部分で扱います。

